<!doctype html><html lang=en><head><meta charset=UTF-8><meta name=viewport content="width=device-width,initial-scale=1"><meta http-equiv=X-UA-Compatible content="ie=edge"><meta http-equiv=Accept-CH content="DPR, Viewport-Width, Width"><link rel=icon href=https://img.icons8.com/external-flaticons-lineal-color-flat-icons/64/000000/external-programmer-mobile-app-development-flaticons-lineal-color-flat-icons.png type=image/gif><link rel=preconnect href=https://fonts.googleapis.com><link rel=preconnect href=https://fonts.gstatic.com crossorigin><link rel=preload as=style href="https://fonts.googleapis.com/css2?family=Alata&family=Lora:ital,wght@0,400;0,500;0,600;0,700;1,400;1,500;1,600;1,700&family=Roboto:ital,wght@0,100;0,300;0,400;0,500;0,700;0,900;1,100;1,300;1,400;1,500;1,700;1,900&display=swap"><link rel=stylesheet href="https://fonts.googleapis.com/css2?family=Alata&family=Lora:ital,wght@0,400;0,500;0,600;0,700;1,400;1,500;1,600;1,700&family=Roboto:ital,wght@0,100;0,300;0,400;0,500;0,700;0,900;1,100;1,300;1,400;1,500;1,700;1,900&display=swap" media=print onload='this.media="all"'><noscript><link href="https://fonts.googleapis.com/css2?family=Alata&family=Lora:ital,wght@0,400;0,500;0,600;0,700;1,400;1,500;1,600;1,700&family=Roboto:ital,wght@0,100;0,300;0,400;0,500;0,700;0,900;1,100;1,300;1,400;1,500;1,700;1,900&display=swap" rel=stylesheet></noscript><link rel=stylesheet href=/css/font.css media=all><meta property="og:title" content="Automated Detection of Performance Regressions in MLIR"><meta property="og:description" content="Automated Detection of Performance Regressions in MLIR Optimizations via Metamorphic Testing"><meta property="og:type" content="article"><meta property="og:url" content="https://poorna2152.github.io/blogs/tech/mlir-performance/"><meta property="article:section" content="blogs"><meta property="article:published_time" content="2026-01-02T00:00:00+00:00"><meta property="article:modified_time" content="2026-01-02T00:00:00+00:00"><meta property="og:site_name" content="Poorna Gunathilaka"><meta name=twitter:card content="summary"><meta name=twitter:title content="Automated Detection of Performance Regressions in MLIR"><meta name=twitter:description content="Automated Detection of Performance Regressions in MLIR Optimizations via Metamorphic Testing"><link rel=stylesheet href=/bootstrap-5/css/bootstrap.min.css media=all><link rel=stylesheet href=/css/header.css media=all><link rel=stylesheet href=/css/footer.css media=all><link rel=stylesheet href=/css/theme.css media=all><style>:root{--text-color:#343a40;--text-secondary-color:#6c757d;--text-link-color:#007bff;--background-color:#eaedf0;--secondary-background-color:#64ffda1a;--primary-color:#007bff;--secondary-color:#f8f9fa;--text-color-dark:#e4e6eb;--text-secondary-color-dark:#b0b3b8;--text-link-color-dark:#ffffff;--background-color-dark:#18191a;--secondary-background-color-dark:#212529;--primary-color-dark:#ffffff;--secondary-color-dark:#212529}body{font-size:1rem;font-weight:400;line-height:1.5;text-align:left}html{background-color:var(--background-color)!important}body::-webkit-scrollbar{height:0;width:8px;background-color:var(--background-color)}::-webkit-scrollbar-track{border-radius:1rem}::-webkit-scrollbar-thumb{border-radius:1rem;background:#b0b0b0;outline:1px solid var(--background-color)}#search-content::-webkit-scrollbar{width:.5em;height:.1em;background-color:var(--background-color)}</style><meta name=description content="Automated Detection of Performance Regressions in MLIR | Poorna Gunathilaka"><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/katex@0.16.8/dist/katex.min.css><script defer src=https://cdn.jsdelivr.net/npm/katex@0.16.8/dist/katex.min.js></script><script defer src=https://cdn.jsdelivr.net/npm/katex@0.16.8/dist/contrib/auto-render.min.js onload='renderMathInElement(document.body,{delimiters:[{left:"$$",right:"$$",display:!0},{left:"$",right:"$",display:!1}]})'></script><style>h1,h2,h3,h4,h5,h6{color:inherit}.dark h1,.dark h2,.dark h3,.dark h4,.dark h5,.dark h6{color:#fff}h1,h2,h3,h4,h5,h6{color:#1a1a1a}.dark code{background-color:rgba(255,255,255,.1);color:#e0e0e0}.dark pre{background-color:rgba(0,0,0,.3);border:1px solid rgba(255,255,255,.1)}code{background-color:#f4f4f4;color:#333}pre{background-color:#f8f8f8;border:1px solid #ddd}code{padding:.2em .4em;border-radius:3px}pre{padding:1em;border-radius:5px;overflow-x:auto}.post-content{line-height:1.8}.dark .post-content{color:#e0e0e0}.post-content{color:#333}.post-content img{max-width:100%;width:auto;height:auto;display:block;margin:1.5rem auto;border-radius:8px;box-shadow:0 2px 8px rgba(0,0,0,.1)}.dark .post-content img{box-shadow:0 2px 8px rgba(0,0,0,.3)}</style><title>Automated Detection of Performance Regressions in MLIR | Poorna Gunathilaka</title></head><body class=light><script>let localStorageValue=localStorage.getItem("pref-theme"),mediaQuery=window.matchMedia("(prefers-color-scheme: dark)").matches;switch(localStorageValue){case"dark":document.documentElement.classList.add("dark"),document.body.classList.add("dark");break;case"light":document.body.classList.remove("dark"),document.documentElement.classList.remove("dark");break;default:mediaQuery&&(document.documentElement.classList.add("dark"),document.body.classList.add("dark"));break}</script><header id=profileHeader><nav class="pt-3 navbar navbar-expand-lg animate"><div class="container-fluid mx-xs-2 mx-sm-5 mx-md-5 mx-lg-5"><a class="navbar-brand primary-font text-wrap" href=/><img src=https://img.icons8.com/external-flaticons-lineal-color-flat-icons/64/000000/external-programmer-mobile-app-development-flaticons-lineal-color-flat-icons.png width=30 height=30 class="d-inline-block align-top">
Poorna Gunathilaka</a><div><input id=search autocomplete=off class="form-control mr-sm-2 d-none d-md-block" placeholder='Ctrl + k to Search...' aria-label=Search oninput=searchOnChange(event)></div><button class=navbar-toggler type=button data-bs-toggle=collapse data-bs-target=#navbarContent aria-controls=navbarContent aria-expanded=false aria-label="Toggle navigation"><svg aria-hidden="true" height="24" viewBox="0 0 16 16" width="24" data-view-component="true"><path fill-rule="evenodd" d="M1 2.75A.75.75.0 011.75 2h12.5a.75.75.0 110 1.5H1.75A.75.75.0 011 2.75zm0 5A.75.75.0 011.75 7h12.5a.75.75.0 110 1.5H1.75A.75.75.0 011 7.75zM1.75 12a.75.75.0 100 1.5h12.5a.75.75.0 100-1.5H1.75z"/></svg></button><div class="collapse navbar-collapse text-wrap primary-font" id=navbarContent><ul class="navbar-nav ms-auto text-center"><li class="nav-item navbar-text d-block d-md-none"><div class=nav-link><input id=search autocomplete=off class="form-control mr-sm-2" placeholder='Ctrl + k to Search...' aria-label=Search oninput=searchOnChange(event)></div></li><li class="nav-item navbar-text"><a class=nav-link href=/#about aria-label=about>About Me</a></li><li class="nav-item navbar-text"><a class=nav-link href=/#experience aria-label=experience>Professional Experience</a></li><li class="nav-item navbar-text"><a class=nav-link href=/#education aria-label=education>Education</a></li><li class="nav-item navbar-text"><a class=nav-link href=/#projects aria-label=projects>Key Projects</a></li><li class="nav-item navbar-text"><a class=nav-link href=/#contact aria-label=contact>Get In Touch</a></li><li class="nav-item navbar-text"><a class=nav-link href=/blogs title="Blog posts">Blog</a></li><li class="nav-item navbar-text"><div class=text-center><button id=theme-toggle><svg id="moon" xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M21 12.79A9 9 0 1111.21 3 7 7 0 0021 12.79z"/></svg><svg id="sun" xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><circle cx="12" cy="12" r="5"/><line x1="12" y1="1" x2="12" y2="3"/><line x1="12" y1="21" x2="12" y2="23"/><line x1="4.22" y1="4.22" x2="5.64" y2="5.64"/><line x1="18.36" y1="18.36" x2="19.78" y2="19.78"/><line x1="1" y1="12" x2="3" y2="12"/><line x1="21" y1="12" x2="23" y2="12"/><line x1="4.22" y1="19.78" x2="5.64" y2="18.36"/><line x1="18.36" y1="5.64" x2="19.78" y2="4.22"/></svg></button></div></li></ul></div></div></nav></header><div id=content><article class=py-5><div class=container><div class="row justify-content-center"><div class="col-lg-8 col-md-10 col-sm-12"><h1 class=mb-3>Automated Detection of Performance Regressions in MLIR</h1><div class=mb-3><span class=text-muted><small>January 2, 2026 | By Poorna Gunathilaka</small></span></div><div class=mb-4><span class="badge bg-secondary me-1">mlir</span>
<span class="badge bg-secondary me-1">fuzzer</span>
<span class="badge bg-secondary me-1">stablehlo</span>
<span class="badge bg-secondary me-1">jax</span>
<span class="badge bg-secondary me-1">titanfuzz</span>
<span class="badge bg-secondary me-1">e-graph</span>
<span class="badge bg-secondary me-1">compiler</span></div><hr class=my-4><div class=post-content><h3 id=what-is-mlir-and-why-does-it-matter>What is MLIR and Why Does It Matter?</h3><p>Compiler infrastructure has historically been fragmented. You had one representation for the high-level language (like the TensorFlow graph) and a completely different one for the low-level machine code (like LLVM IR). Moving between these levels often resulted in lost optimization opportunities.</p><p>MLIR (Multi-Level Intermediate Representation) solves this by providing a unified infrastructure. It allows compilers to define &ldquo;dialects&rdquo;—modular levels of abstraction that can mix and match. It serves as the backbone for modern machine learning compilers like XLA (used by TensorFlow, JAX, and PyTorch).</p><p>When you write code in JAX, it doesn&rsquo;t go straight to machine code. It gets lowered into the <strong>StableHLO</strong> dialect, then usually to the <strong>Linalg</strong> or <strong>Affine</strong> dialects, and finally to LLVM IR or NVVM for hardware execution.</p><p>Because MLIR sits right in the middle of this pipeline, it is the critical path for performance. If an MLIR pass handles a loop inefficiently, the final application runs slowly, regardless of how fast the hardware is.</p><p><img src=/img/xla.png alt=XLA></p><h3 id=the-problem-correctness-vs-performance>The Problem: Correctness vs. Performance</h3><p>Most compiler testing focuses on <strong>correctness</strong>. We run fuzzers to answer the question: <em>&ldquo;Does the compiler crash, or does it produce the wrong number?&rdquo;</em></p><p>However, in High-Performance Computing (HPC), a program that produces the right answer but takes 10x longer to run is effectively broken. These are <strong>Silent Performance Regressions</strong>. They are dangerous because they don&rsquo;t throw errors; they just silently degrade the efficiency of the underlying hardware.</p><p>Detecting them is hard. To test correctness, you just need to check the output. To test performance, you typically need an &ldquo;oracle&rdquo;—you need to know exactly how fast the code <em>should</em> run. For random, generated test cases, calculating that theoretical speed is impossible.</p><p>I recently built a framework to automate performance testing for MLIR without needing a ground-truth oracle.</p><h3 id=the-approach-metamorphic-testing-relations-and-tools>The Approach: Metamorphic Testing Relations and Tools</h3><p>Since we can&rsquo;t predict absolute performance for random inputs, we look at relative performance using <strong>Metamorphic Testing</strong>. I defined three Metamorphic Relations (MRs) that a healthy MLIR compiler should satisfy, utilizing specific tools to define the expected performance behaviors.</p><p><img src=/img/flow-mlir.png alt=Flow></p><p><strong>1. Polyhedral Optimization Relation (via Polygeist)</strong></p><ul><li><strong>Relation:</strong> Code optimized with polyhedral techniques should outperform a standard scalar CPU baseline.</li><li><strong>The Tool:</strong> To define the optimized baseline, I used <strong>Polygeist</strong>.</li><li><strong>Why:</strong> Standard compilers often struggle to automatically identify complex loop optimizations like tiling, parallelization, and fusion in scientific code. Polygeist uses the polyhedral model—a mathematical framework for analyzing loop nests—to automatically apply these advanced transformations. It lowers code to MLIR&rsquo;s Affine dialect, representing a &ldquo;best-case&rdquo; scenario for CPU execution that the standard pipeline should aim to match.</li></ul><p><strong>2. Semantic Equivalence Relation (via DialEgg)</strong></p><ol><li><strong>Distributivity (Factorization):</strong> Optimizes two matrix multiplications sharing a common operand.<ul><li><em>Original:</em> $D = (A \cdot B) + (A \cdot C)$ (Cost: $\approx 2N^3$)</li><li><em>Rewritten:</em> $D = A \cdot (B + C)$ (Cost: $\approx N^3$)</li><li><em>Benefit:</em> Halves the dominant operation count.</li></ul></li><li><strong>Associativity Reordering:</strong> Optimizes chain multiplication based on dimension sizes.<ul><li><em>Original:</em> $D = (A \cdot B) \cdot C$</li><li><em>Rewritten:</em> $D = A \cdot (B \cdot C)$</li><li><em>Benefit:</em> The compiler should choose the order that generates the smallest intermediate matrix, minimizing FLOPs.</li></ul></li><li><strong>Diagonal Scaling:</strong> Detects when a matrix multiplication is actually a scaling operation.<ul><li><em>Original:</em> $D = A \cdot \text{diag}(v)$</li><li><em>Rewritten:</em> $D_{ij} = A_{ij} \cdot v_j$</li><li><em>Benefit:</em> Reduces complexity from cubic $O(N^3)$ to quadratic $O(N^2)$.</li></ul></li></ol><p><strong>3. Hardware Offloading Relation</strong></p><ul><li><strong>Relation:</strong> For sufficient workloads, running on a GPU should be faster than a CPU. This tests the compiler&rsquo;s ability to effectively lower StableHLO to NVVM (NVIDIA&rsquo;s IR) versus LLVM CPU code.</li></ul><h3 id=input-generation-the-compute-bound-requirement>Input Generation: The &ldquo;Compute-Bound&rdquo; Requirement</h3><p>Generating valid inputs for performance testing is significantly harder than for crash testing.</p><p>For the hardware relation (<code>Time(GPU) &lt; Time(CPU)</code>) to hold true, the input program must be <strong>computationally heavy</strong>. If a program is memory-bound (spending all its time moving data rather than calculating), the GPU&rsquo;s massive parallelism provides no advantage, and the overhead of moving data across the PCIe bus actually makes the GPU slower.</p><p>This requirement disqualified standard random code generators, which often produce &ldquo;spaghetti code&rdquo; with low arithmetic intensity.</p><p><strong>Why PolyBench?</strong>
I chose the <strong>PolyBench</strong> benchmark suite as the source of my inputs. PolyBench consists specifically of dense linear algebra kernels (like Matrix Multiplication and solvers) that have high arithmetic intensity. These are exactly the types of programs where a GPU <em>should</em> beat a CPU.</p><p><strong>Why TitanFuzz?</strong>
I extended <strong>TitanFuzz</strong>, an LLM-based fuzzer, because it supports <strong>seed-based generation</strong>. Unlike pure random generation, TitanFuzz allowed me to feed in the high-quality PolyBench kernels as seeds. The LLM could then mutate these seeds to create new test cases while preserving the underlying computationally heavy structure required for meaningful performance comparisons.</p><h3 id=results-and-findings>Results and Findings</h3><p>I evaluated the framework on 45 computational kernels. The data highlighted both successes and failures in the current MLIR ecosystem.</p><p><strong>1. Polyhedral Optimizations are Consistent</strong>
The relation <code>Time(Polygeist) &lt; Time(Baseline)</code> held up well. Using Polygeist to raise code to the Affine dialect consistently improved performance.</p><ul><li><strong>Results:</strong> Speedups ranged from <strong>1.50x</strong> (for <code>atax</code>) to <strong>8.45x</strong> (for <code>3mm</code>), confirming that the polyhedral path is stable.</li></ul><p><img src=/img/polyhedral.png alt="Polyhedral results"></p><p><strong>2. Semantic Rewrites Work</strong>
The relation based on DialEgg rewrites also passed consistently.</p><ul><li><strong>Results:</strong> The tool successfully optimized complex expressions, yielding speedups between <strong>1.15x</strong> and <strong>2.48x</strong>.</li></ul><p><img src=/img/dialegg.png alt="Semantic Rewrite results"></p><p><strong>3. The GPU &ldquo;Crossover&rdquo; Issue</strong>
The hardware relation (<code>Time(GPU) &lt; Time(CPU)</code>) revealed a significant limitation in simple performance testing.</p><p>We found that we cannot simply assert that the GPU is faster. The relationship is strictly dependent on the <strong>Input Size ($N$)</strong>.</p><ul><li><strong>At $N=2048$ (Large):</strong> The GPU path was massively faster. Compute-bound kernels like <code>comm</code> saw speedups of <strong>49.72x</strong>.</li><li><strong>At $N=512$ (Small):</strong> The GPU path often failed. The <code>gesummv</code> kernel ran at <strong>0.67x</strong> speed (a 33% slowdown) compared to the CPU.</li></ul><p><img src=/img/cpu-gpu.png alt="CPU vs GPU results"></p><h3 id=summary-and-future-work>Summary and Future Work</h3><p>This project demonstrates that we don&rsquo;t need a theoretical oracle to find performance bugs. However, the results from the GPU experiments show that a simple &ldquo;GPU > CPU&rdquo; rule is insufficient.</p><p>To make this test robust, we need to calculate the <strong>Crossover Point</strong>.</p><p>We cannot blindly check if the GPU is faster. We need a mathematical equation—likely based on the kernel&rsquo;s <strong>Arithmetic Intensity</strong> (FLOPs per byte) and the hardware&rsquo;s data transfer bandwidth—to predict the minimum input size $N$ required to hide the latency overhead.</p><p>Implementing this cost-model equation into the testing framework is the next step. It would allow the test to automatically skip the &ldquo;GPU vs CPU&rdquo; check for small inputs where the CPU is expected to win, preventing false positives and focusing the test on genuine regressions at scale. You can find the source code and the paper of this project <a href=https://github.com/poorna2152/mmlir>here</a>.</p></div><hr class=my-4><div class=mt-5><div class=row><div class="col-md-6 mb-3"><a href=/blogs/fitness/the-last-layer/ class=text-decoration-none><div class=card><div class=card-body><small class=text-muted>← Previous Post</small><h6 class=card-title>The Last Layer: Rethinking My Fitness, From Cholesterol to VO2 Max</h6></div></div></a></div></div></div></div></div></div></article></div><footer><div class="text-center pt-2"></div><div class="container py-4"><div class="row justify-content-center"><div class="col-md-4 text-center"><div class=pb-2><a href=https://poorna2152.github.io/ title="Poorna Gunathilaka"><img alt="Footer logo" src=https://img.icons8.com/external-flaticons-lineal-color-flat-icons/64/000000/external-programmer-mobile-app-development-flaticons-lineal-color-flat-icons.png height=40px width=40px></a></div>&copy; 2026 All Rights Reserved<div class=text-secondary>Made with
<span class=text-danger>&#10084;
</span>and
<a href=https://github.com/gurusabarish/hugo-profile target=_blank title="Designed and developed by gurusabarish">Hugo Profile</a></div></div></div></div></footer><script src=/bootstrap-5/js/bootstrap.bundle.min.js></script><script>document.body.className.includes("light")&&(document.documentElement.classList.add("dark"),document.body.classList.add("dark"),localStorage.setItem("pref-theme","dark"))</script><script>document.getElementById("theme-toggle").addEventListener("click",()=>{document.body.className.includes("dark")?(document.body.classList.remove("dark"),document.documentElement.classList.remove("dark"),localStorage.setItem("pref-theme","light")):(document.body.classList.add("dark"),document.documentElement.classList.add("dark"),localStorage.setItem("pref-theme","dark"))});var tooltipTriggerList=[].slice.call(document.querySelectorAll('[data-bs-toggle="tooltip"]')),tooltipList=tooltipTriggerList.map(function(e){return new bootstrap.Tooltip(e)})</script><script src=/js/search.js></script><section id=search-content class=py-2><div class=container id=search-results></div></section></body></html>