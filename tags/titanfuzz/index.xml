<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Titanfuzz on Poorna Gunathilaka</title><link>https://poorna2152.github.io/tags/titanfuzz/</link><description>Recent content in Titanfuzz on Poorna Gunathilaka</description><generator>Hugo -- gohugo.io</generator><language>en-us</language><lastBuildDate>Fri, 02 Jan 2026 00:00:00 +0000</lastBuildDate><atom:link href="https://poorna2152.github.io/tags/titanfuzz/index.xml" rel="self" type="application/rss+xml"/><item><title>Automated Detection of Performance Regressions in MLIR</title><link>https://poorna2152.github.io/blogs/tech/mlir-performance/</link><pubDate>Fri, 02 Jan 2026 00:00:00 +0000</pubDate><guid>https://poorna2152.github.io/blogs/tech/mlir-performance/</guid><description>What is MLIR and Why Does It Matter? Compiler infrastructure has historically been fragmented. You had one representation for the high-level language (like the TensorFlow graph) and a completely different one for the low-level machine code (like LLVM IR). Moving between these levels often resulted in lost optimization opportunities.
MLIR (Multi-Level Intermediate Representation) solves this by providing a single, unified infrastructure. It allows compilers to define &amp;ldquo;dialects&amp;rdquo;â€”modular levels of abstraction that can mix and match.</description></item></channel></rss>